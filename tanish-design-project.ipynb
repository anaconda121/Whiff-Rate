{"metadata":{"kernelspec":{"name":"python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d","display_name":"Python 3.9.0 64-bit"},"language_info":{"name":"python","version":"3.9.0","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"metadata":{"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import learning_curve\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix as cm\n","import pickle\n","import time"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import ShuffleSplit\n","# function for plotting learning curve, taken from skcikit-learn.org\n","def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n","    if axes is None:\n","        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n","    axes[0].set_title(title)\n","    if ylim is not None:\n","        axes[0].set_ylim(*ylim)\n","    axes[0].set_xlabel(\"Training examples\")\n","    axes[0].set_ylabel(\"Score\")\n","\n","    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n","        train_sizes=train_sizes, return_times=True)\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    fit_times_mean = np.mean(fit_times, axis=1)\n","    fit_times_std = np.std(fit_times, axis=1)\n","\n","    # Plot learning curve\n","    axes[0].grid()\n","    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                         train_scores_mean + train_scores_std, alpha=0.1,\n","                         color=\"r\")\n","    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                         test_scores_mean + test_scores_std, alpha=0.1,\n","                         color=\"g\")\n","    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","                 label=\"Training score\")\n","    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","                 label=\"Cross-validation score\")\n","    axes[0].legend(loc=\"best\")\n","\n","    # Plot n_samples vs fit_times\n","    axes[1].grid()\n","    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n","    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n","                         fit_times_mean + fit_times_std, alpha=0.1)\n","    axes[1].set_xlabel(\"Training examples\")\n","    axes[1].set_ylabel(\"fit_times\")\n","    axes[1].set_title(\"Scalability of the model\")\n","\n","    # Plot fit_time vs score\n","    axes[2].grid()\n","    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n","    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n","                         test_scores_mean + test_scores_std, alpha=0.1)\n","    axes[2].set_xlabel(\"fit_times\")\n","    axes[2].set_ylabel(\"Score\")\n","    axes[2].set_title(\"Performance of the model\")\n","\n","    return plt"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["data_raw = pd.read_csv('pitches.csv')"]},{"cell_type":"code","source":["# Print out size, shape, and column names\n","print(\"size: \" + str(data_raw.size))\n","print(\"shape: \" + str(data_raw.shape))\n","print(\"columns: \" + str(data_raw.columns))"],"metadata":{"trusted":true},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["size: 114686160\nshape: (2867154, 40)\ncolumns: Index(['px', 'pz', 'start_speed', 'end_speed', 'spin_rate', 'spin_dir',\n       'break_angle', 'break_length', 'break_y', 'ax', 'ay', 'az', 'sz_bot',\n       'sz_top', 'type_confidence', 'vx0', 'vy0', 'vz0', 'x', 'x0', 'y', 'y0',\n       'z0', 'pfx_x', 'pfx_z', 'nasty', 'zone', 'code', 'type', 'pitch_type',\n       'event_num', 'b_score', 'ab_id', 'b_count', 's_count', 'outs',\n       'pitch_num', 'on_1b', 'on_2b', 'on_3b'],\n      dtype='object')\n"]}]},{"cell_type":"code","source":["df = data_raw\n","# drop everything except swinging strikes and foul balls\n","df = df[df.code.isin(['S', 'F'])]\n","# Convert S/F to 1 and 0 to measure ROC AUC\n","sf = {'S': 1, 'F': 0}\n","df.code = [sf[item] for item in df.code]\n","# only 2-strike counts\n","df = df[df.s_count == 2]\n","# dropping useless columns and rows with null values\n","df = df.drop([\"zone\", \"type_confidence\", \"pitch_type\", \"ab_id\", \"event_num\"], axis = 1)\n","df = df.drop([\"y0\", \"type\", \"b_score\", \"outs\", \"pitch_num\", \"b_count\", \"s_count\", \"on_1b\", \"on_2b\", \"on_3b\"], axis = 1)\n","df = df.dropna()"],"metadata":{"trusted":true},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\n"]}]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["(185990, 25)\n"]},{"output_type":"execute_result","data":{"text/plain":["Index(['px', 'pz', 'start_speed', 'end_speed', 'spin_rate', 'spin_dir',\n","       'break_angle', 'break_length', 'break_y', 'ax', 'ay', 'az', 'sz_bot',\n","       'sz_top', 'vx0', 'vy0', 'vz0', 'x', 'x0', 'y', 'z0', 'pfx_x', 'pfx_z',\n","       'nasty', 'code'],\n","      dtype='object')"]},"metadata":{},"execution_count":21}],"source":["print(df.shape)\n","df.columns"]},{"cell_type":"code","source":["# balance out the cases\n","strikes = df[df.code == 1]\n","fouls = df[df.code == 0]\n","fouls = fouls[0:len(strikes)]\n","tojoin = [strikes, fouls]\n","df = pd.concat(tojoin)\n","print(strikes.shape)\n","df.shape"],"metadata":{"trusted":true},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["(92995, 25)\n"]},{"output_type":"execute_result","data":{"text/plain":["(185990, 25)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["with open(\"Models/scaled_models/mlp.pkl\", \"rb\") as mlpr:\n","    mlp = pickle.load(mlpr)\n","with open(\"Models/unscaled_models/ab.pkl\", \"rb\") as abr:\n","    ab = pickle.load(abr)\n","with open(\"Models/unscaled_models/gb.pkl\", \"rb\") as gbr:\n","    gb = pickle.load(gbr)\n","with open(\"Models/unscaled_models/rf.pkl\", \"rb\") as rfr:\n","    rf = pickle.load(rfr)\n","with open(\"Models/scaled_models/ab_scaled.pkl\", \"rb\") as abr:\n","    ab_scaled = pickle.load(abr)\n","with open(\"Models/scaled_models/gb_scaled.pkl\", \"rb\") as gbr:\n","    gb_scaled = pickle.load(gbr)\n","with open(\"Models/scaled_models/rf_scaled.pkl\", \"rb\") as rfr:\n","    rf_scaled = pickle.load(rfr)\n","with open(\"Models/scaled_models/vc.pkl\", \"rb\") as evcr:\n","    vc = pickle.load(evcr)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import sklearn.model_selection as tts\n","features_train, features_test, labels_train, labels_test = tts.train_test_split(df.transpose()[:24].transpose(), df.code, test_size = 0.3, random_state = 666)\n","# IMPORTANT: DO NOT TOUCH VAL UNTIL VALIDATION PHASE!!\n","features_test, features_val, labels_test, labels_val = tts.train_test_split(features_test, labels_test, test_size = 0.3, random_state = 420)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Scaling data helps with MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(features_train)\n","features_train_scaled = scaler.transform(features_train)\n","features_test_scaled = scaler.transform(features_test)\n","features_val_scaled = scaler.transform(features_val)"]},{"cell_type":"code","execution_count":25,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 60.8459997177124 seconds\n"]}],"source":["st = time.time()\n","mlp = MLPClassifier(random_state=1, max_iter=2000).fit(features_train_scaled, labels_train)\n","# fig, axes = plt.subplots(3, 2, figsize=(10,15))\n","# cv = ShuffleSplit(n_splits=2, test_size=0.3, random_state=1)\n","# plot_learning_curve(mlp, \"MLP Learning curves\", features_train_scaled, labels_train, axes=axes[:,0], ylim=(0.7,1.01),cv=cv,n_jobs=4)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7813708170110352\n0.8536681130873278\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[16892,  2526],\n","       [ 6013, 13626]], dtype=int64)"]},"metadata":{},"execution_count":28}],"source":["print(mlp.score(features_test_scaled, labels_test))\n","print(roc_auc_score(labels_test, mlp.predict_proba(features_test_scaled)[:,1]))\n","cm(labels_test, mlp.predict(features_test_scaled))\n","# 16892 true negatives, 2526 false positives, 6013 false negatives, 13626 true positives"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 52.30151295661926 seconds\n"]}],"source":["st = time.time()\n","rf = RandomForestClassifier().fit(features_train, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7209719128453286\n","0.7902904808977868\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[ 1282, 18136],\n","       [  931, 18708]], dtype=int64)"]},"metadata":{},"execution_count":30}],"source":["print(rf.score(features_test, labels_test))\n","print(roc_auc_score(labels_test, rf.predict_proba(features_test)[:,1]))\n","cm(labels_test, rf.predict(features_test_scaled))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 52.26684236526489 seconds\n"]}],"source":["st = time.time()\n","rf_scaled = RandomForestClassifier().fit(features_train_scaled, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(rf_scaled.score(features_test_scaled, labels_test))\n","print(roc_auc_score(labels_test, rf_scaled.predict_proba(features_test_scaled)[:,1]))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 671.4226229190826 seconds\n"]}],"source":["st = time.time()\n","gb = GradientBoostingClassifier(loss='exponential', n_estimators = 1000).fit(features_train, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))\n","# fig, axes = plt.subplots(3, 2, figsize=(10,15))\n","# title = \"Learning Curve with Gradient Boosting Classifier\"\n","# plot_learning_curve(gb, title, features_train, labels_train)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7792457177970659\n","0.8510920235705091\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[16937,  2481],\n","       [ 6141, 13498]], dtype=int64)"]},"metadata":{},"execution_count":34}],"source":["print(gb.score(features_test, labels_test))\n","print(roc_auc_score(labels_test, gb.predict_proba(features_test)[:,1]))\n","cm(labels_test, gb.predict(features_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["st = time.time()\n","gb_scaled = GradientBoostingClassifier(loss='exponential', n_estimators = 1000).fit(features_train_scaled, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.780705123281358"]},"metadata":{},"execution_count":17}],"source":["gb_scaled.score(features_test_scaled, labels_test)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 523.5434520244598 seconds\n"]}],"source":["st = time.time()\n","ab = AdaBoostClassifier(n_estimators=1000).fit(features_train, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7544358245640986"]},"metadata":{},"execution_count":19}],"source":["ab.score(features_test, labels_test)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 358.23775148391724 seconds\n"]}],"source":["st = time.time()\n","ab_scaled = AdaBoostClassifier(n_estimators=1000).fit(features_train_scaled, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7544358245640986"]},"metadata":{},"execution_count":21}],"source":["print(ab_scaled.score(features_test_scaled, labels_test))\n","print(roc_auc_score(labels_test, ab_scaled.predict_proba(features_test_scaled)))\n","cm(labels_test, ab_scaled.predict(features_test_scaled))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitted in 1057.8590025901794 seconds\n"]}],"source":["st = time.time()\n","vc = VotingClassifier(estimators=[('gbs', gb_scaled), ('abs', ab_scaled), ('rfs', rf_scaled), ('mlps', mlp)], voting = 'hard').fit(features_train_scaled, labels_train)\n","print(\"Fitted in %s seconds\" % (time.time() - st))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7753795734439409"]},"metadata":{},"execution_count":23}],"source":["print(vc.score(features_test_scaled, labels_test))\n","print(roc_auc_score(labels_test, vc.predict_proba(features_test_scaled)))\n","cm(labels_test, vc.predict(features_test_scaled))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["with open(\"Models/scaled_models/mlp.pkl\", \"wb\") as mlpw:\n","    pickle.dump(mlp, mlpw)\n","with open(\"Models/unscaled_models/ab.pkl\", \"wb\") as abw:\n","    pickle.dump(ab, abw)\n","with open(\"Models/unscaled_models/gb.pkl\", \"wb\") as gbw:\n","    pickle.dump(gb, gbw)\n","with open(\"Models/unscaled_models/rf.pkl\", \"wb\") as rfw:\n","    pickle.dump(rf, rfw)\n","with open(\"Models/scaled_models/ab_scaled.pkl\", \"wb\") as abw:\n","    pickle.dump(ab_scaled, abw)\n","with open(\"Models/scaled_models/gb_scaled.pkl\", \"wb\") as gbw:\n","    pickle.dump(gb_scaled, gbw)\n","with open(\"Models/scaled_models/rf_scaled.pkl\", \"wb\") as rfw:\n","    pickle.dump(rf_scaled, rfw)\n","with open(\"Models/scaled_models/vc.pkl\", \"wb\") as evcw:\n","    pickle.dump(vc, evcw)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}